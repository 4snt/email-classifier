# Email Classifier â€” MVP (FastAPI + DDD-lite)

MVP **enxuto** para classificar e-mails como **Produtivo** ou **Improdutivo** e gerar uma **resposta sugerida**.
Entrada pode ser **JSON** (subject/body) ou **arquivo** `.pdf`/`.txt`. Arquitetura **hexagonal** (ports/adapters) com use case Ãºnico.

## âœ¨ Entregas do MVP

- `POST /classify` aceita **JSON** e **multipart** (`.pdf`/`.txt`)
- **NLP bÃ¡sico** (preprocess + tokenizaÃ§Ã£o + stopwords PT/EN)
- **Classificador rule-based** (padrÃ£o) | **LLM opcional** via `OPENAI_API_KEY`
- **Resposta sugerida** conforme categoria
- `GET /health` | Swagger em `/docs`

## ğŸš€ Rodar

```bash
pip install -r requirements.txt
uvicorn app.main:app --reload
# API: http://127.0.0.1:8000  |  Docs: http://127.0.0.1:8000/docs
```

> Para usar LLM, exporte `OPENAI_API_KEY` **antes** de iniciar.

### Docker

```bash
docker build -t email-classifier:latest .
docker run --rm -p 8000:8000 -e OPENAI_API_KEY=$OPENAI_API_KEY email-classifier:latest
```

## ğŸ”Œ Endpoints

- `GET /health` â†’ `{ "status": "ok" }`
- `POST /classify` (JSON): `{"subject":"...", "body":"...", "sender":"..."}`
- `POST /classify` (arquivo): `-F "file=@/caminho/email.txt|.pdf"`

## ğŸ§± Estrutura

```
app/
  main.py | bootstrap.py
  application/ (use_cases/)
  domain/ (entities, ports, errors)
  infrastructure/ (extractors, nlp, classifiers, responders)
```

## âš™ï¸ Config

- `.env.example` inclui `OPENAI_API_KEY=` (opcional). Sem LLM â†’ usa rule-based.

## ğŸ“ PrÃ³ximos passos

- Pesos e testes no rule-based
- OCR para PDFs escaneados
- MÃ©tricas/logs e CI no GitHub Actions

## ğŸ“„ LicenÃ§a

Definir (ex.: MIT) ao publicar.
